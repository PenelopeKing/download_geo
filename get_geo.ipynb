{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "96317d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Ignoring invalid distribution -eyboard (/usr/local/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ooper (/usr/local/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yping-extensions (/usr/local/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: traitlets in /usr/local/anaconda3/lib/python3.9/site-packages (5.9.0)\n",
      "\u001b[33mWARNING: Ignoring invalid distribution -eyboard (/usr/local/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ooper (/usr/local/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -umpy (/usr/local/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -yping-extensions (/usr/local/anaconda3/lib/python3.9/site-packages)\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# import necessary packages\n",
    "\n",
    "!pip install traitlets\n",
    "\n",
    "from geofetch import Geofetcher\n",
    "import pysradb.sraweb\n",
    "import pandas as pd\n",
    "import os\n",
    "import urllib.request\n",
    "import sys\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, Dropdown, Button, Text\n",
    "#from IPython.utils import traitlets\n",
    "import traitlets\n",
    "from traitlets import dlink"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4e630",
   "metadata": {},
   "source": [
    "### Function 1 : get metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ab534d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_series_files(gse):\n",
    "    \"\"\"\n",
    "    uses geofetch to get supplemental data files using a GSE code\n",
    "    input: gse (str)\n",
    "    output: df of supp data file info\n",
    "    \"\"\"\n",
    "    # get supplemental data\n",
    "    geof = Geofetcher(processed=True, data_source='all', just_metadata=True, discard_soft = True)\n",
    "    proj = geof.get_projects(gse)\n",
    "    \n",
    "    # check if supplemental data exists\n",
    "    gse_series = gse + '_series'\n",
    "    if gse_series in proj.keys():\n",
    "        df = proj[gse_series].sample_table\n",
    "        # clean columns, names for consistency when concatenating df's\n",
    "        keep = ['file','sample_name', 'series_sample_organism', 'series_sample_id', 'file_url', 'series_overall_design','series_type']\n",
    "        df= df[keep]\n",
    "        return df.rename(columns={'series_sample_organism': 'organism_name',\n",
    "                                 'sample_name':'title',\n",
    "                                 'series_sample_id':'GSM',\n",
    "                                 'series_overall_design':'description'}).reset_index(drop=True)\n",
    "    else:\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8125227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_descriptions(gse, where_save):\n",
    "    \"\"\"\n",
    "    Gets a compliation of metadata for selection\n",
    "    input: gse (str), where_save (str)\n",
    "    output: df & downloads .csv\n",
    "    \"\"\"\n",
    "    ### input validation ###\n",
    "    if (not type(gse) is str) or (gse[:3] != 'GSE'):\n",
    "        return \"input must be a string starting with GSE followed by numbers\"\n",
    "    ### end of validation ###\n",
    "    \n",
    "    # gets relevant information\n",
    "    geo_helper = pysradb.sraweb.SRAweb()\n",
    "    gsm_srx = geo_helper.gse_to_gsm(gse)\n",
    "    srp = geo_helper.gse_to_srp(gse)['study_accession'][0] # gets the srp code\n",
    "    df = geo_helper.sra_metadata(srp) # contains meta info of data for gse\n",
    "    output = pd.merge(gsm_srx, df)\n",
    "    \n",
    "    # column and name cleaning for consistency for easier concat of df's\n",
    "    cols_keep = ['run_accession', 'experiment_title', 'organism_name', 'experiment_alias', 'experiment_desc','total_spots', 'total_size', 'run_total_spots','run_total_bases']\n",
    "    output =  output[cols_keep].rename(columns={'run_accession':'file',\n",
    "                                'experiment_title':'title', \n",
    "                                 'experiment_desc': 'description',\n",
    "                                'experiment_alias' : 'GSM'})\n",
    "    series_df = get_series_files(gse)\n",
    "    if series_df.shape != (0,0):\n",
    "        # concat srr (fastq) and supp series data frames\n",
    "        output = pd.concat([output, series_df], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    # turn output into csv, download it\n",
    "    filename = gse + '_metadata.csv'\n",
    "    filename = os.path.join(where_save, filename)\n",
    "    output.to_csv(filename)\n",
    "    print('\\nA .csv version of this dataframe has been saved as {} at {}'.format(filename, filename))\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7aec84",
   "metadata": {},
   "source": [
    "### Function 2: download data from metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9b68cd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_files(csv, path):\n",
    "    \"\"\"\n",
    "    downloads files that partial csv contains (all rows)\n",
    "    input: csv path and download path\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv)\n",
    "    \n",
    "    # split btw fastq and supplemental files\n",
    "    lst = df['file']\n",
    "    srr_to_download = lst[lst.apply(lambda x: 'SRR' in x)].to_list()\n",
    "    supp_to_download = lst[~lst.apply(lambda x: 'SRR' in x)].index.to_list()\n",
    "    \n",
    "    # makes folder for files to download\n",
    "    download_path = os.path.join(path, 'downloaded_files')\n",
    "    try: \n",
    "        os.mkdir(download_path)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    ### downloading supplemental files ###\n",
    "    print('Downloading supplemental files...\\n')\n",
    "    for supp_idx in supp_to_download:\n",
    "        download_link = 'https://' + df.iloc[supp_idx]['file_url'].split(\"//\")[-1]\n",
    "        file_name = os.path.join(download_path, download_link.split(\"/\")[-1])\n",
    "        urllib.request.urlretrieve(download_link, file_name)\n",
    "\n",
    "    ### downloading fastq files ###\n",
    "    print('Downloading FASTQ files... this make take a bit...\\n')\n",
    "    for srr in srr_to_download:\n",
    "        # prefetch srr files for quicker download\n",
    "        download_path = os.path.join(path, 'downloaded_files')\n",
    "        pf_cmd = 'prefetch {} -O {}'.format(srr, download_path)\n",
    "        print(pf_cmd)\n",
    "        os.system(pf_cmd)\n",
    "        # download fastq\n",
    "        path = os.path.join(download_path,os.path.join(srr, srr+'.sra'))\n",
    "        fastq_cmd = 'fasterq-dump --outdir {} {}'.format(os.path.join(download_path, srr), path)\n",
    "        print(fastq_cmd)\n",
    "        os.system(fastq_cmd)\n",
    "\n",
    "    print('\\nComplete\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f3ac8",
   "metadata": {},
   "source": [
    "### GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "967b94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pretty_table(csv_file):\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Display the DataFrame using IPython display\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7082c8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maximum_k(directory):\n",
    "    # Get all files in the directory\n",
    "    files = os.listdir(directory)\n",
    "    \n",
    "    # Filter for files starting with Partial_\n",
    "    partial_files = [f for f in files if f.startswith(\"Partial_\")]\n",
    "    if len(partial_files) == 0:\n",
    "        return 0\n",
    "   \n",
    "    # Extract the k values from each filename\n",
    "    k_values = [int(f.split(\"_\")[1]) for f in partial_files]\n",
    "   \n",
    "    # Return the maximum k value\n",
    "    return max(k_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f49d56a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def browse_and_select_rows(csv_file, column_name):\n",
    "    # Read the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df.rename(columns={'Unnamed: 0':'index'})\n",
    "\n",
    "    # Create a dropdown widget to select items from the column\n",
    "    options_list = [''] +df[column_name].unique().tolist()\n",
    "    dropdown = Dropdown(options= options_list)\n",
    "    \n",
    "    # Create an input text widget for the save path\n",
    "    save_path_input = Text(value='./', description='Save Path:')\n",
    "    \n",
    "    # Create a button widget for saving and downloading\n",
    "    button = Button(description='Save and Download')\n",
    "    \n",
    "    # Enable tab-completion for the save path input\n",
    "    traitlets.dlink((save_path_input, 'value'), (save_path_input, 'placeholder'))\n",
    "    \n",
    "    # Create an empty DataFrame to store selected rows\n",
    "    selected_rows_df = pd.DataFrame()\n",
    "    \n",
    "    # Function to display filtered rows based on the selected item\n",
    "    def display_filtered_rows(selected_item):\n",
    "        nonlocal selected_rows_df\n",
    "        \n",
    "        # Filter the DataFrame based on the selected item\n",
    "        filtered_df = df[df[column_name] == selected_item]\n",
    "        \n",
    "        # Append the filtered rows to the selected rows DataFrame\n",
    "        selected_rows_df = pd.concat([selected_rows_df, filtered_df], ignore_index=True)\n",
    "        \n",
    "        # Display the selected rows\n",
    "        display(filtered_df)\n",
    "        \n",
    "        # Print the growing list of selected rows\n",
    "        print(\"Selected Rows:\")\n",
    "        for i in range(len(selected_rows_df)):\n",
    "            row_entry = str(selected_rows_df.loc[i, column_name])[:60] + '...' if len(str(selected_rows_df.loc[i, column_name])) > 60 else str(selected_rows_df.loc[i, column_name])\n",
    "            print(f\"Row {i+1}: {row_entry}\")\n",
    "        print()  # Print an empty line for separation\n",
    "        \n",
    "    # Function to handle the save and download button click event\n",
    "    def save_and_download(_):\n",
    "        nonlocal selected_rows_df\n",
    "        \n",
    "        # Check if any rows are selected\n",
    "        if selected_rows_df.empty:\n",
    "            print(\"No rows are selected.\")\n",
    "            return\n",
    "        \n",
    "        # Get the save path directory from the input text widget\n",
    "        save_directory = save_path_input.value\n",
    "        \n",
    "        # Get the directory and file part of the original CSV file path\n",
    "        directory = os.path.dirname(csv_file)\n",
    "        file_name = os.path.basename(csv_file)\n",
    "        file_part = os.path.splitext(file_name)[0]\n",
    "        file_extension = os.path.splitext(file_name)[1]\n",
    "        \n",
    "        # Find the next available k for the Partial_k file name in the directory\n",
    "        \n",
    "        # Find the next available k for the Partial_k file name in the directory\n",
    "        k = get_maximum_k(save_directory)\n",
    "        # Create the Partial_k file name\n",
    "        partial_k_filename = f\"Partial_{k+1}_{file_part}.csv\"\n",
    "        \n",
    "\n",
    "        # Combine the save directory, partial_k file name, and save path to form the final save path\n",
    "        save_path = os.path.join(save_directory, partial_k_filename)\n",
    "        \n",
    "        # Write the selected rows to a new CSV file\n",
    "        selected_rows_df.to_csv(save_path, index=False)\n",
    "        \n",
    "        # Print the save path and exit the program\n",
    "        print(f\"Saved CSV file: {save_path}\")\n",
    "        \n",
    "        # download the files in partial csv\n",
    "        download_files(save_path, save_directory)\n",
    "        \n",
    "        # Clear the selected rows DataFrame for the next iteration\n",
    "        selected_rows_df = pd.DataFrame()\n",
    "    \n",
    "    # Connect the dropdown widget to the display function\n",
    "    interact(display_filtered_rows, selected_item=dropdown)\n",
    "    \n",
    "    # Connect the button widget to the save and download function\n",
    "    button.on_click(save_and_download)\n",
    "    \n",
    "    # Display the input text widget and button widget\n",
    "    display(save_path_input, button) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b1b66e",
   "metadata": {},
   "source": [
    "### Testing \n",
    "using GSE code from Glass SALL1 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0ca4c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metadata folder: /home/pking/Desktop/download_geo/project_name\n",
      "Trying GSE226090 (not a file) as accession...\n",
      "Trying GSE226090 (not a file) as accession...\n",
      "Skipped 0 accessions. Starting now.\n",
      "\u001b[38;5;200mProcessing accession 1 of 1: 'GSE226090'\u001b[0m\n",
      "Total number of processed SERIES files found is: 20\n",
      "Expanding metadata list...\n",
      "Expanding metadata list...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finished processing 1 accession(s)\n",
      "Cleaning soft files ...\n",
      "No files found. No data to save. File /home/pking/Desktop/download_geo/project_name/GSE226090_samples/GSE226090_samples.csv won't be created\n",
      "Unifying and saving of metadata... \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A .csv version of this dataframe has been saved as /home/pking/outputs/GSE226090_metadata.csv at /home/pking/outputs/GSE226090_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "# this example uses SALL1 data\n",
    "sal1_gse = 'GSE226090'\n",
    "output = get_descriptions(sal1_gse, '/home/pking/outputs/');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8324b5e1",
   "metadata": {},
   "source": [
    "Usage Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb3ebc95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>title</th>\n",
       "      <th>organism_name</th>\n",
       "      <th>GSM</th>\n",
       "      <th>description</th>\n",
       "      <th>total_spots</th>\n",
       "      <th>total_size</th>\n",
       "      <th>run_total_spots</th>\n",
       "      <th>run_total_bases</th>\n",
       "      <th>file_url</th>\n",
       "      <th>series_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR23613876</td>\n",
       "      <td>GSM7063497: PU1+ nuclei, H3K27ac Input ChIPseq...</td>\n",
       "      <td>Mus musculus</td>\n",
       "      <td>GSM7063497</td>\n",
       "      <td>GSM7063497: PU1+ nuclei, H3K27ac Input ChIPseq...</td>\n",
       "      <td>10680471</td>\n",
       "      <td>656843723</td>\n",
       "      <td>10680471</td>\n",
       "      <td>2157455142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR23613877</td>\n",
       "      <td>GSM7063496: PU1+ nuclei, H3K27ac Input ChIPseq...</td>\n",
       "      <td>Mus musculus</td>\n",
       "      <td>GSM7063496</td>\n",
       "      <td>GSM7063496: PU1+ nuclei, H3K27ac Input ChIPseq...</td>\n",
       "      <td>9623829</td>\n",
       "      <td>594129205</td>\n",
       "      <td>9623829</td>\n",
       "      <td>1944013458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR23613880</td>\n",
       "      <td>GSM7063493: Olig2+ nuclei, H3K27ac Input ChIPs...</td>\n",
       "      <td>Mus musculus</td>\n",
       "      <td>GSM7063493</td>\n",
       "      <td>GSM7063493: Olig2+ nuclei, H3K27ac Input ChIPs...</td>\n",
       "      <td>7819623</td>\n",
       "      <td>481494974</td>\n",
       "      <td>7819623</td>\n",
       "      <td>1579563846</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR23613882</td>\n",
       "      <td>GSM7063492: Olig2+ nuclei, H3K27ac Input ChIPs...</td>\n",
       "      <td>Mus musculus</td>\n",
       "      <td>GSM7063492</td>\n",
       "      <td>GSM7063492: Olig2+ nuclei, H3K27ac Input ChIPs...</td>\n",
       "      <td>10676675</td>\n",
       "      <td>661452028</td>\n",
       "      <td>10676675</td>\n",
       "      <td>2156688350</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR23613885</td>\n",
       "      <td>GSM7063489: NeuN+ nuclei, H3K27ac Input ChIPse...</td>\n",
       "      <td>Mus musculus</td>\n",
       "      <td>GSM7063489</td>\n",
       "      <td>GSM7063489: NeuN+ nuclei, H3K27ac Input ChIPse...</td>\n",
       "      <td>8012260</td>\n",
       "      <td>499551998</td>\n",
       "      <td>8012260</td>\n",
       "      <td>1618476520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file                                              title  \\\n",
       "0  SRR23613876  GSM7063497: PU1+ nuclei, H3K27ac Input ChIPseq...   \n",
       "1  SRR23613877  GSM7063496: PU1+ nuclei, H3K27ac Input ChIPseq...   \n",
       "2  SRR23613880  GSM7063493: Olig2+ nuclei, H3K27ac Input ChIPs...   \n",
       "3  SRR23613882  GSM7063492: Olig2+ nuclei, H3K27ac Input ChIPs...   \n",
       "4  SRR23613885  GSM7063489: NeuN+ nuclei, H3K27ac Input ChIPse...   \n",
       "\n",
       "  organism_name         GSM  \\\n",
       "0  Mus musculus  GSM7063497   \n",
       "1  Mus musculus  GSM7063496   \n",
       "2  Mus musculus  GSM7063493   \n",
       "3  Mus musculus  GSM7063492   \n",
       "4  Mus musculus  GSM7063489   \n",
       "\n",
       "                                         description total_spots total_size  \\\n",
       "0  GSM7063497: PU1+ nuclei, H3K27ac Input ChIPseq...    10680471  656843723   \n",
       "1  GSM7063496: PU1+ nuclei, H3K27ac Input ChIPseq...     9623829  594129205   \n",
       "2  GSM7063493: Olig2+ nuclei, H3K27ac Input ChIPs...     7819623  481494974   \n",
       "3  GSM7063492: Olig2+ nuclei, H3K27ac Input ChIPs...    10676675  661452028   \n",
       "4  GSM7063489: NeuN+ nuclei, H3K27ac Input ChIPse...     8012260  499551998   \n",
       "\n",
       "  run_total_spots run_total_bases file_url series_type  \n",
       "0        10680471      2157455142      NaN         NaN  \n",
       "1         9623829      1944013458      NaN         NaN  \n",
       "2         7819623      1579563846      NaN         NaN  \n",
       "3        10676675      2156688350      NaN         NaN  \n",
       "4         8012260      1618476520      NaN         NaN  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22630427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614a7fbf691541babc065b83c637221f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='selected_item', options=('', 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5ca8ef227f4259a23ed25b2a830986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='./', description='Save Path:', placeholder='./')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e11766d55a14e548432e5f1db76c60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Save and Download', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV file: /home/pking/outputs/Partial_3_GSE226090_metadata.csv\n",
      "Downloading supplemental files...\n",
      "\n",
      "Downloading FASTQ files... this make take a bit...\n",
      "\n",
      "prefetch SRR23613876 -O /home/pking/outputs/downloaded_files\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-10T23:18:13 prefetch.3.0.5: Current preference is set to retrieve SRA Normalized Format files with full base quality scores.\n",
      "2023-07-10T23:18:13 prefetch.3.0.5: 1) Downloading 'SRR23613876'...\n",
      "2023-07-10T23:18:13 prefetch.3.0.5: SRA Normalized Format file is being retrieved, if this is different from your preference, it may be due to current file availability.\n",
      "2023-07-10T23:18:13 prefetch.3.0.5:  Downloading via HTTPS...\n",
      "2023-07-10T23:19:03 prefetch.3.0.5:  HTTPS download succeed\n",
      "2023-07-10T23:19:04 prefetch.3.0.5:  'SRR23613876' is valid\n",
      "2023-07-10T23:19:04 prefetch.3.0.5: 1) 'SRR23613876' was downloaded successfully\n",
      "2023-07-10T23:19:04 prefetch.3.0.5: 'SRR23613876' has 0 unresolved dependencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasterq-dump --outdir /home/pking/outputs/downloaded_files/SRR23613876 /home/pking/outputs/downloaded_files/SRR23613876/SRR23613876.sra\n",
      "\n",
      "Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "spots read      : 10,680,471\n",
      "reads read      : 21,360,942\n",
      "reads written   : 21,360,942\n"
     ]
    }
   ],
   "source": [
    "browse_and_select_rows('/home/pking/get_geo/GSE226090_metadata.csv', 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3898e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
